\documentclass[sigplan,screen]{acmart}

\input{preamble}
\input{macros}

\begin{document}

\title[Approximating Type Stability in the Julia JIT (work in progress)]%
{Approximating Type Stability in the Julia JIT\\(work in progress)}

\input{metadata}

\maketitle

\section{Introduction}

The scientific computing community has long been of two minds about the language
technology best suited for the task. On the one hand, the exploratory nature of
programming with raw datasets and mathematical models with many parameters calls
for modern convenience features like dynamic typing and garbage collection. On
the other, crunching numbers may require to squeeze every CPU cycle available.
Accordingly, the language market in this area is split into productivity
languages (Python, MATLAB, R) and high-performance oriented languages (C,
C++, Fortran).

The split nature of the language landscape in the area of scientific
computing calls for a question: can we have the best of both worlds? Julia
attempts to answer in the positive.

On the surface, the Juila language has a lot of pythonistic feeling to it.
Consider the following function that sums an array of elements but clamps the
summands above the given threshold.
%
\begin{lstlisting}
  function sum(v, t)
    res = v[1]
    for i = 2:length(v)
      elm  = v[i] < t ? v[i] : t
      res = res + elm
    end
    res
  end
\end{lstlisting}
%
What is striking about this code is the absence of type annotations either on the
function arguments or anywhere locally. Of course, it is possible to call
\c{sum} with a string and a number and get a run-time failure. On the other hand,
and no less of a surprise, when called with the right arguments the code gets
JIT-compiled and performs on par with equivalent C code.

Julia's competitive performance is documented both in the language manual and in
academic papers~\cite{oopsla18a}. One of the key techniques enabling
essential optimizations is based on the code property called \emph{type
stability}~\cite{Pelenitsyn21}. While well-understood on the IR level, the
property has been elusive for end users: it is mentioned in the manual and on
many forum threads but still does not have a clear source-level model for it.
In this short paper we propose the first algorithm to approximate this highly
dynamic property statically. In particular, we
\begin{itemize}

  \item give an informal description of type stability as it comes up in
  the practice of Julia programming (\secref{sec:back}; largely following~\cite{Pelenitsyn21});

  \item discuss challenges to model type stability statically and the relation
  of the task to the full-fledged type inference (\secref{sec:arrive});

  \item give an algorithm to approximate type stability statically (\secref{sec:algo});

  \item remark on implementation (\secref{sec:impl}) and
  evaluation of the algorithm (\secref{sec:eval}) --- both work in progress.
\end{itemize}

% \section{A Typeful Language in The Untyped Universe}%
\section{A Type Stability Primer}%
% \section{Julia: Productivity And Performance Reconciled}
\label{sec:back}

\subsection{Multiple Dispatch in Julia}%

The Julia language is designed around multiple dispatch~\cite{BezansonEKS17}.
Programs consist of \emph{functions} that are implemented by multiple
\emph{methods}; there is nothing more to a Julia function than just a name. Each
method is identified by a distinct type signature. At run time, the Julia
implementation dispatches a function call to the \emph{most specific} method by
comparing the types of the arguments to the types of the parameters of all
methods of that function. For example, the call to the \c{+} function in the
example from the introduction can dispatch to one out of over two hundreds
methods for \c{+} in the standard library alone (packages can add more methods
to a function). % TODO: \figref{fig:plus}.

% TODO: figure how to make figure* work...
% \begin{figure*}
% \begin{lstlisting}[language=julia]
% # 184 methods for generic function "+":
% [1] +(x::T, y::T) where T<:Union{Int128, Int16, Int32, Int64, Int8, UInt128, UInt16, UInt32, UInt64, UInt8} in Base at int.jl:87
% [2] +(x::T, y::T) where T<:Union{Float16, Float32, Float64} in Base at float.jl:383[3] +(::Missing) in Base at missing.jl:100
% ...
% \end{lstlisting}
% \caption{Methods from the standard library}\label{plus}\label{fig:plus}
% \Description{Several of 206 methods for the \c{+} function in the Julia standard
%   library as of Julia 1.8.5}
% \end{figure*}


Julia supports a rich type language for defining method signatures. Base types
consist of either bits types (i.e. types with a direct binary representation,
like integers) or record types (called structs in Julia). Both bits types and
record types, referred to as \emph{concrete types}, can have supertypes, but all
supertypes are \emph{abstract types}. Abstract types are arranged into a
subtyping hierarchy rooted at the built-in \c{Any} type. Every value in the
program has a unique type tag that can be accessed via the \c{typeof} function.
%
The type language allows for further composition of these base
types using unions, tuples, and bounded existential constructors; the result of
composition can be abstract or concrete. \citet{oopsla18b} gives a detailed
discussion of the type language and of subtyping.

Any function call in a program, such as \c{res+elm} in the example above,
requires choosing one of the methods of the target function. \emph{Method
dispatch} is a multi-step process. First, the implementation obtains the
concrete types of arguments. Second, it retrieves applicable methods by checking
for subtyping between argument types and type annotations of the methods. Next,
it sorts these methods into subtype order. Finally, the call is dispatched to
the most specific method---a method such that no other applicable method is its
strict subtype. If no such method exists, an error is produced.

Function calls are pervasive in Julia, and their efficiency is crucial for
performance. However, the multi-step dispatch mechanism
make the process slow. To attain acceptable performance, the compiler attempts
to remove as many dispatch operations as it can. This optimization leverages
run-time type information whenever a method is compiled, i.e., when it is called
for the first time with a novel set of argument types.  These types are used by
the compiler to infer types in the method body. Then, this type information
frequently allows the compiler to devirtualize and inline the function calls
within a method~\cite{aigner}, thus improving performance. However, this
optimization is not always possible: if type inference cannot produce a
sufficiently specific type, then the call cannot be devirtualized.

\subsection{Type Stability: A Key To Performance?}

To illustrate a profound effect that type inference precision can have on
performance, consider the \c{sum} function from the introduction benchmarked in
three scenarios differing only in input types. Assuming a random array of integers
called \c{vint} and a random array of floating-point numbers called \c{vflt}
(both consisting of 10K elements)
compare the median running time of the following three calls to \c{sum}:
\begin{itemize}

  \item \c{sum(vint, 0)}~--- 1.397 microseconds
  \item \c{sum(vflt, 0.5)}~--- 11.489 microseconds
  \item \c{sum(vint, 0.5)}~--- 64.623 microseconds
\end{itemize}

When a performance regression occurs, it is common for Julia developers to study
the intermediate representation produced by the compiler. To facilitate this,
the language provides a utilty, \c{code_warntype}, that shows Julia's
intermediate representation of the code along with the inferred types for a given function
invocation. Types that are imprecise, i.e. abstract, show up in red: they
indicate that concrete type of a run-time value may vary from run to run.
%
In the first two benchmarks, the Julia compiler is able to deduce a concrete return
type of the method (\c{Int} and \c{Float} correspondingly), but the type of the last one
reported as \c{Union\{Int, Float\}}, which is an abstract type.
%
Such type imprecision can impact performance in two ways. First,
the \c{res} variable has to be boxed, adding a level of indirection to
any operation performed therein. Second, it is harder for
the compiler to devirtualize and inline consecutive calls, thus requiring
dynamic dispatch.

Julia's compilation model is designed to accommodate source programs
with flexible types. Yet, to make such programs efficient, the compiler
creates an \emph{instance} of each source method for each distinct tuple of
argument types. Thus, even if the programmer does not provide any type
annotations, like in the \c{sum} example, the compiler will create method
instances for \emph{concrete} input types seen during
an execution. For example, the three benchmarks shown above will make the
compiler create three distinct method instances.
Because method instances have more precise argument types, the compiler can
leverage them to produce more efficient code and infer more precise return types.

In Julia parlance, a method is called \emph{type stable} if, given a concrete
input type, it is possible to infer a concrete output type. The \c{sum} function
is not type stable because for the input type \c{Tuple\{Vector\{Int\},
Float64\}}\footnote{Tuple types encode several input arguments in Julia.}
the return type can be either \c{Int} or \c{Float64}.

\citet{Pelenitsyn21} formalize type stability as it
relates to program \emph{execution} by building a formal model of a
type-specializing just-in-time compiler that does its main job at run time.
In this work, we set to approximate the property of type stability for
arbitrary Julia code statically, without running the code in question.

%\section{Approximating Type Stability Statically}\label{chap:approx}
\section{Inferring Type Stability Versus Inferring Types}%
\label{sec:arrive}

A natural idea for inferring type stability in Julia would be to formulate it as
a forward static analysis: being an abstract or concrete type is one bit of
information that has a known value at the input (concrete) and should be
propagated to the output, possibly changing on the way.

To test the static analysis idea, consider a positive example first: the
identity function.
% TODO: there's a weird break in the listing near page break (see PDF)
\begin{lstlisting}
  function id(x)
    x
  end
\end{lstlisting}
%
It is straightforward to infer that, given any concrete input type, the return
value is also concretely typed: the one bit of information carries over to the
result in one step.

However, another example---the increment function---shows that the task quickly
becomes unwieldy.
%
\begin{lstlisting}
  function inc(x)
    x + 1
  end
\end{lstlisting}
%
Concreteness of the result returned by \c{inc} depends on concreteness of
the result of the call to \c{+}. In turn, the property of the return type of
\c{+} depends on which \c{+} method Julia will dispatch to at run time.
There are about two hundred method implementations of \c{+} in the standard
library alone, and packages add more. Some of those methods are type stable
(e.g. \c{+(::Int64,::Int64)}), and some of them are not (e.g.
\lstinline|+(::Rational{Bool},::Rational{Bool}|)
\footnote{%
  The reason for the
  \c{+(::Rational\{Bool\},::Rational\{Bool\})} method to be type
  unstable is not important, but in a nutshell, Julia has made a questionable
  design decision about the return type of \c{{+}(::Bool,::Bool)}, which in the
  current implementation is \c{Int}
  (see discussion \url{https://github.com/JuliaLang/julia/issues/19168}),
  and when adding two rational numbers with boolean components, depending on the
  values of the summands, you get back either \c{Rational\{Bool\}} or
  \c{Rational\{Int\}}.}
).
Therefore,
to infer the property of interest, in general,
we need to predict which methods are selected at run time.

The \c{inc} example shows that inferring type stability of Julia code
requires
reasoning about %which methods will be called at run time, % repetition of prev sentence
%which, in a language with dynamic dispatch, leads
multiple dynamic dispatch, which leads
to reasoning about the \emph{types} of intermediate values rather than only
the concreteness bit. But if there was a tool for computing type information
beforehand, a special-purpose analysis for type stability would not be needed:
it suffices to ask the tool for the type of the return value and
check if that type is concrete.
%The observation of interactions between type
%stability and type inference can be formulated
This observation leads to the following conjecture:

\begin{conjecture}
  Inferring type stability of a Julia method statically is no easier than
  performing type inference of that method.
\end{conjecture}

A complete type inference algorithm would allow for checking type stability of
Julia code. But should type inference be implemented from scratch? There are two reasons to
not go this way.
\begin{enumerate}

  \item It is not clear that inferring types for source-level Julia code
  without changing anything in the language
  can yield a meaningful result (more on this see~\cite{Chung23}).
  For instance, in the \c{inc} example, a sound return type cannot be
  much better than \c{Any}.

  \item Julia already has a built-in type inference engine, which
    is modeled as a black box in~\cite{Pelenitsyn21}.
    The engine is used for code optimizations.
    Thus, analyzing type stability based on a custom type inference
    algorithm
    can produce results that diverge from Julia, misleading the users
    about potential optimizations.
    This would be of limited usage for Julia users.
\end{enumerate}

\section{An Algorithm To Approximate Type Stability}%
\label{sec:algo}

If our predictions for type stability are to align with the Julia
implementation, the analysis should closely model Julia's run-time behavior,
as described in~\cite{Pelenitsyn21}. The type-specializing JIT-compiler
from~\cite{Pelenitsyn21} makes optimization decisions based on \emph{concrete
  input types} with the help of Juila's type inference engine.
Therefore, the algorithm for
predicting these decisions statically considers all (or as many as possible,
see~\secref{sec:approx:space}) allowed concrete input types of a method.
\figref{fig:infer-ts} describes this algorithm at a high level.

\input{figs/infer-ts.tex}

Let us consider every step of the algorithm described
on~\figref{fig:infer-ts} and explain its meaning using an example.
The list below also assigns the numbers to each step in the algorithm.
\begin{enumerate}

  \item The input of the algorithm is a Julia method. Methods in Julia are
  represented by run-time objects of type \c{Method} and can be manipulated as
  all other objects (e.g. stored in collections, responding to field accesses, etc.).

  For example, consider the \c{length} method from Julia's standard library. We can
  get the corresponding \c{Method} object using the standard \c{@which} macro
  applied to an application of the \c{length} method. This can be done in the
  Julia REPL (signified by the \texttt{julia>} prefix).

\begin{minipage}{.92\columnwidth}
\begin{lstlisting}[style=jterm]
  julia> @which length([1,2,3])
  length(a::Array) in Base at array.jl:215
\end{lstlisting}
\end{minipage}

  The output shows that the given \c{length}-call will dispatch to the
  method defined in the \texttt{Base} module (Julia-speak for the standard
  library). The output also shows the location of the method in the
  standard library and, most importantly for us, the signature of the
  method. In fact, what we see here is a pretty-printed representation of
  the \c{Method} object representing a particular Julia method.

  \item The first task of the algorithm is to get the input type of the given
  method. This is possible through querying the \c{sig} field of the method object.

  Building on the example above, we can get the signature of the \c{length}
  method as follows:

\begin{minipage}{.92\columnwidth}
\begin{lstlisting}[style=jterm]
  julia> m = @which length([1,2,3]);

  julia> m.sig
  Tuple{typeof(length), Array}
\end{lstlisting}
\end{minipage}

  A signature of a method
  contains the special singleton function
  type (\c{typeof(...)}) as the first component, and the rest is (easy to
  convert to) the type of the input --- an $n$-tuple. In this example, the type of
  the input is 1-tuple, consisting of the existential array type
  \c{Array\{T, N\}\ where T where N} abbreviated simply as \c{Array}\footnote{%
A user can always look under the abbreviation using the \c{dump} function.}.

  \item The input type can be either concrete, which, in Julia, means that there can
  be no proper subtypes of that type, or abstract. In either case, the choice on the
  current step will enter the loop at least once, because for concrete input type,
  the check holds once trivially (e.g.\ there is exactly one concrete
  subtype of the concrete type \c{Int} --- it is \c{Int} itself).

  If the input type is abstract, we need a procedure enumerating all concrete
  subtypes of it. An implementation for this procedure is discussed in the next
  section, but it suffices to treat is as a black box for now.

  In the case of the \c{length} method, the input type, \c{Array}, is
  an existential type and hence abstract. Therefore, the enumeration procedure
  should have yielded a concrete subtype of \c{Array}. Assume that
  the concrete type is \c{Array\{Float64, 1\}}.

  \item Running Julia's type inference for a given method and a given concrete input
  type is done by calling Julia's standard \c{code\_typed} function.
  The only issue with the function is that it expects a function object as a
  part of the input, not a method object. But getting from a method to the
  corresponding function is possible using the signature field discussed above,
  and, in particular, the singleton function type contained in the first component
  of the \c{sig} field: accessing the single function object using the function
  type is possible via the \c{instance} field.

  Running type inference for the \c{length} method and the concrete input type
  \c{Array\{Float64, 1\}} could be done as shown on \figref{fig:julia-type-infer}.
  The return value is an array of \c{CodeInfo} objects that represent
  the type-annotated method bodies of all methods that a call with the given input type
  could dispatch to (for a concrete input type and no ambiguities in method
  definitions, the resulting array always contains exactly one element).
  Method bodies are transformed into
  a lower-level intermediate representation.
  In the running example, the
  method body contains a single call to an intrinsic Julia function that is
  known to return a value of type \c{Int64}.

  \begin{figure}%[hbt]
% \begin{minipage}{.92\textwidth}
% \begin{verbatim}
\begin{lstlisting}[style=jterm]
  julia> code_typed(m.sig.parameters[1].instance,
                    (Array{Float64, 1},),
                    optimize=false)
  1-element Vector{Any}:
   CodeInfo(
  1 - %1 = Base.arraylen(a)::Int64
  +--      return %1
  ) => Int64
\end{lstlisting}
    \caption{Running Julia's built-in type inferencer}%
    \label{fig:julia-type-infer}
  \end{figure}
% \end{verbatim}
% \end{minipage}

  \item Concreteness of the inferred return type is checked
  with the standard Julia \c{isconcretetype} predicate.
  In the running example,
  the return type of \c{length} is inferred to be \c{Int64}
  for the concrete input type \c{Array\{Float64, 1\}}.
  Since \c{Int64} is a concrete type,
  following the second decision element on \figref{fig:infer-ts}brings us back to
  the start of the loop. After that, we try another concrete subtype of the input type,
  if there is any.
\end{enumerate}

\section{Implementation}%
\label{sec:impl}

The first practical consideration of the algorithm as shown is termination. It
is clear that the algorithm does not terminate for some inputs. Consider the
\c{length} example: its input type is the existential \c{Array} type, which
means that possible concrete input types may be:
\begin{itemize}

  \item \c{Array\{1, Int\}}
  \item \c{Array\{1, Array\{1, Int\}\}}
  \item \c{Array\{1, Array\{1, Array\{1, Int\}\}\}}
  \item etc.
\end{itemize}

The issue of termination is close to another one: a search space blow up.
In the standard library alone, there are over five hundreds immediate subtypes
of \c{Any} and every concrete subtype of those can be use to instantiate the
\c{Array} type when inferring stability of \c{length}. Although finite, this
space can be simply too large to exhaust in a reasonable time.

Our intention is to develop certain heuristics to perform an early termination
of the algorithm. The simplest heuristic of this sort is to employ a fuel
parameter that gives an arbitrary upper bound for the number of steps we are
allowed to perform before we give up.

Another implementation concern is step 3 where we need to generate a concrete
subtype of the input type. Although there is no built-in facility for this
task, Julia allows getting immediate subtypes of a given type using the
\c{subtypes} method. As our current implementation shows, with enough care, it
is not hard to enumerate concrete subtypes by applying the \c{subtypes} method
iteratively.

\section{Evaluation}%
\label{sec:eval}

\citet{Pelenitsyn21} analyzed the type stability of a corpus of open-source Julia
packages dynamically via executing test suites of the packages and inspecting the
resulting method instances collected from the internal state of the virtual
machine. We propose to run our algorithm for statically inferring type stability
over the same packages and match the results.


\bibliography{bib/jv,bib/all,bib/lj}

\end{document}
